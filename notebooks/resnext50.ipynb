{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''ResNeXt models for Keras.\n",
    "# Reference\n",
    "- [Aggregated Residual Transformations for Deep Neural Networks](https://arxiv.org/pdf/1611.05431.pdf))\n",
    "'''\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "\n",
    "import keras\n",
    "import warnings\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Dense, Lambda\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import GlobalAveragePooling2D, GlobalMaxPooling2D, MaxPooling2D\n",
    "from keras.layers import Input\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.utils.layer_utils import convert_all_kernels_in_model\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras_applications.imagenet_utils import _obtain_input_shape\n",
    "import keras.backend as K\n",
    "\n",
    "CIFAR_TH_WEIGHTS_PATH = ''\n",
    "CIFAR_TF_WEIGHTS_PATH = ''\n",
    "CIFAR_TH_WEIGHTS_PATH_NO_TOP = ''\n",
    "CIFAR_TF_WEIGHTS_PATH_NO_TOP = ''\n",
    "\n",
    "IMAGENET_TH_WEIGHTS_PATH = ''\n",
    "IMAGENET_TF_WEIGHTS_PATH = ''\n",
    "IMAGENET_TH_WEIGHTS_PATH_NO_TOP = ''\n",
    "IMAGENET_TF_WEIGHTS_PATH_NO_TOP = ''\n",
    "\n",
    "\n",
    "def ResNext(input_shape=None, depth=29, cardinality=8, width=64, weight_decay=5e-4,\n",
    "            include_top=True, weights=None, input_tensor=None,\n",
    "            pooling=None, classes=10):\n",
    "    \"\"\"Instantiate the ResNeXt architecture. Note that ,\n",
    "        when using TensorFlow for best performance you should set\n",
    "        `image_data_format=\"channels_last\"` in your Keras config\n",
    "        at ~/.keras/keras.json.\n",
    "        The model are compatible with both\n",
    "        TensorFlow and Theano. The dimension ordering\n",
    "        convention used by the model is the one\n",
    "        specified in your Keras config file.\n",
    "        # Arguments\n",
    "            depth: number or layers in the ResNeXt model. Can be an\n",
    "                integer or a list of integers.\n",
    "            cardinality: the size of the set of transformations\n",
    "            width: multiplier to the ResNeXt width (number of filters)\n",
    "            weight_decay: weight decay (l2 norm)\n",
    "            include_top: whether to include the fully-connected\n",
    "                layer at the top of the network.\n",
    "            weights: `None` (random initialization)\n",
    "            input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "                to use as image input for the model.\n",
    "            input_shape: optional shape tuple, only to be specified\n",
    "                if `include_top` is False (otherwise the input shape\n",
    "                has to be `(32, 32, 3)` (with `tf` dim ordering)\n",
    "                or `(3, 32, 32)` (with `th` dim ordering).\n",
    "                It should have exactly 3 inputs channels,\n",
    "                and width and height should be no smaller than 8.\n",
    "                E.g. `(200, 200, 3)` would be one valid value.\n",
    "            pooling: Optional pooling mode for feature extraction\n",
    "                when `include_top` is `False`.\n",
    "                - `None` means that the output of the model will be\n",
    "                    the 4D tensor output of the\n",
    "                    last convolutional layer.\n",
    "                - `avg` means that global average pooling\n",
    "                    will be applied to the output of the\n",
    "                    last convolutional layer, and thus\n",
    "                    the output of the model will be a 2D tensor.\n",
    "                - `max` means that global max pooling will\n",
    "                    be applied.\n",
    "            classes: optional number of classes to classify images\n",
    "                into, only to be specified if `include_top` is True, and\n",
    "                if no `weights` argument is specified.\n",
    "        # Returns\n",
    "            A Keras model instance.\n",
    "        \"\"\"\n",
    "\n",
    "    if weights not in {'cifar10', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `cifar10` '\n",
    "                         '(pre-training on CIFAR-10).')\n",
    "\n",
    "    if weights == 'cifar10' and include_top and classes != 10:\n",
    "        raise ValueError('If using `weights` as CIFAR 10 with `include_top`'\n",
    "                         ' as true, `classes` should be 10')\n",
    "\n",
    "    if type(depth) == int:\n",
    "        if (depth - 2) % 9 != 0:\n",
    "            raise ValueError('Depth of the network must be such that (depth - 2)'\n",
    "                             'should be divisible by 9.')\n",
    "\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=32,\n",
    "                                      min_size=8,\n",
    "                                      data_format=K.image_data_format(),\n",
    "                                      require_flatten=include_top)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    x = __create_res_next(classes, img_input, include_top, depth, cardinality, width,\n",
    "                          weight_decay, pooling)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='resnext')\n",
    "\n",
    "    # load weights\n",
    "    if weights == 'cifar10':\n",
    "        if (depth == 29) and (cardinality == 8) and (width == 64):\n",
    "            # Default parameters match. Weights for this model exist:\n",
    "\n",
    "            if K.image_data_format() == 'channels_first':\n",
    "                if include_top:\n",
    "                    weights_path = get_file('resnext_cifar_10_8_64_th_dim_ordering_th_kernels.h5',\n",
    "                                            CIFAR_TH_WEIGHTS_PATH,\n",
    "                                            cache_subdir='models')\n",
    "                else:\n",
    "                    weights_path = get_file('resnext_cifar_10_8_64_th_dim_ordering_th_kernels_no_top.h5',\n",
    "                                            CIFAR_TH_WEIGHTS_PATH_NO_TOP,\n",
    "                                            cache_subdir='models')\n",
    "\n",
    "                model.load_weights(weights_path)\n",
    "\n",
    "                if K.backend() == 'tensorflow':\n",
    "                    warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                                  'are using the Theano '\n",
    "                                  'image dimension ordering convention '\n",
    "                                  '(`image_dim_ordering=\"th\"`). '\n",
    "                                  'For best performance, set '\n",
    "                                  '`image_dim_ordering=\"tf\"` in '\n",
    "                                  'your Keras config '\n",
    "                                  'at ~/.keras/keras.json.')\n",
    "                    convert_all_kernels_in_model(model)\n",
    "            else:\n",
    "                if include_top:\n",
    "                    weights_path = get_file('resnext_cifar_10_8_64_tf_dim_ordering_tf_kernels.h5',\n",
    "                                            CIFAR_TF_WEIGHTS_PATH,\n",
    "                                            cache_subdir='models')\n",
    "                else:\n",
    "                    weights_path = get_file('resnext_cifar_10_8_64_tf_dim_ordering_tf_kernels_no_top.h5',\n",
    "                                            CIFAR_TF_WEIGHTS_PATH_NO_TOP,\n",
    "                                            cache_subdir='models')\n",
    "\n",
    "                model.load_weights(weights_path)\n",
    "\n",
    "                if K.backend() == 'theano':\n",
    "                    convert_all_kernels_in_model(model)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def ResNextImageNet(input_shape=None, depth=[3, 4, 6, 3], cardinality=32, width=4, weight_decay=5e-4,\n",
    "                    include_top=True, weights=None, input_tensor=None,\n",
    "                    pooling=None, classes=1000):\n",
    "    \"\"\" Instantiate the ResNeXt architecture for the ImageNet dataset. Note that ,\n",
    "        when using TensorFlow for best performance you should set\n",
    "        `image_data_format=\"channels_last\"` in your Keras config\n",
    "        at ~/.keras/keras.json.\n",
    "        The model are compatible with both\n",
    "        TensorFlow and Theano. The dimension ordering\n",
    "        convention used by the model is the one\n",
    "        specified in your Keras config file.\n",
    "        # Arguments\n",
    "            depth: number or layers in the each block, defined as a list.\n",
    "                ResNeXt-50 can be defined as [3, 4, 6, 3].\n",
    "                ResNeXt-101 can be defined as [3, 4, 23, 3].\n",
    "                Defaults is ResNeXt-50.\n",
    "            cardinality: the size of the set of transformations\n",
    "            width: multiplier to the ResNeXt width (number of filters)\n",
    "            weight_decay: weight decay (l2 norm)\n",
    "            include_top: whether to include the fully-connected\n",
    "                layer at the top of the network.\n",
    "            weights: `None` (random initialization) or `imagenet` (trained\n",
    "                on ImageNet)\n",
    "            input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "                to use as image input for the model.\n",
    "            input_shape: optional shape tuple, only to be specified\n",
    "                if `include_top` is False (otherwise the input shape\n",
    "                has to be `(224, 224, 3)` (with `tf` dim ordering)\n",
    "                or `(3, 224, 224)` (with `th` dim ordering).\n",
    "                It should have exactly 3 inputs channels,\n",
    "                and width and height should be no smaller than 8.\n",
    "                E.g. `(200, 200, 3)` would be one valid value.\n",
    "            pooling: Optional pooling mode for feature extraction\n",
    "                when `include_top` is `False`.\n",
    "                - `None` means that the output of the model will be\n",
    "                    the 4D tensor output of the\n",
    "                    last convolutional layer.\n",
    "                - `avg` means that global average pooling\n",
    "                    will be applied to the output of the\n",
    "                    last convolutional layer, and thus\n",
    "                    the output of the model will be a 2D tensor.\n",
    "                - `max` means that global max pooling will\n",
    "                    be applied.\n",
    "            classes: optional number of classes to classify images\n",
    "                into, only to be specified if `include_top` is True, and\n",
    "                if no `weights` argument is specified.\n",
    "        # Returns\n",
    "            A Keras model instance.\n",
    "        \"\"\"\n",
    "\n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `imagenet` '\n",
    "                         '(pre-training on ImageNet).')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as imagenet with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    "\n",
    "    if type(depth) == int and (depth - 2) % 9 != 0:\n",
    "        raise ValueError('Depth of the network must be such that (depth - 2)'\n",
    "                         'should be divisible by 9.')\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=224,\n",
    "                                      min_size=112,\n",
    "                                      data_format=K.image_data_format(),\n",
    "                                      require_flatten=include_top)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    x = __create_res_next_imagenet(classes, img_input, include_top, depth, cardinality, width,\n",
    "                                   weight_decay, pooling)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='resnext')\n",
    "\n",
    "    # load weights\n",
    "    if weights == 'imagenet':\n",
    "        if (depth == [3, 4, 6, 3]) and (cardinality == 32) and (width == 4):\n",
    "            # Default parameters match. Weights for this model exist:\n",
    "\n",
    "            if K.image_data_format() == 'channels_first':\n",
    "                if include_top:\n",
    "                    weights_path = get_file('resnext_imagenet_32_4_th_dim_ordering_th_kernels.h5',\n",
    "                                            IMAGENET_TH_WEIGHTS_PATH,\n",
    "                                            cache_subdir='models')\n",
    "                else:\n",
    "                    weights_path = get_file('resnext_imagenet_32_4_th_dim_ordering_th_kernels_no_top.h5',\n",
    "                                            IMAGENET_TH_WEIGHTS_PATH_NO_TOP,\n",
    "                                            cache_subdir='models')\n",
    "\n",
    "                model.load_weights(weights_path)\n",
    "\n",
    "                if K.backend() == 'tensorflow':\n",
    "                    warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                                  'are using the Theano '\n",
    "                                  'image dimension ordering convention '\n",
    "                                  '(`image_dim_ordering=\"th\"`). '\n",
    "                                  'For best performance, set '\n",
    "                                  '`image_dim_ordering=\"tf\"` in '\n",
    "                                  'your Keras config '\n",
    "                                  'at ~/.keras/keras.json.')\n",
    "                    convert_all_kernels_in_model(model)\n",
    "            else:\n",
    "                if include_top:\n",
    "                    weights_path = get_file('resnext_imagenet_32_4_tf_dim_ordering_tf_kernels.h5',\n",
    "                                            IMAGENET_TF_WEIGHTS_PATH,\n",
    "                                            cache_subdir='models')\n",
    "                else:\n",
    "                    weights_path = get_file('resnext_imagenet_32_4_tf_dim_ordering_tf_kernels_no_top.h5',\n",
    "                                            IMAGENET_TF_WEIGHTS_PATH_NO_TOP,\n",
    "                                            cache_subdir='models')\n",
    "\n",
    "                model.load_weights(weights_path)\n",
    "\n",
    "                if K.backend() == 'theano':\n",
    "                    convert_all_kernels_in_model(model)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def __initial_conv_block(input, weight_decay=5e-4):\n",
    "    ''' Adds an initial convolution block, with batch normalization and relu activation\n",
    "    Args:\n",
    "        input: input tensor\n",
    "        weight_decay: weight decay factor\n",
    "    Returns: a keras tensor\n",
    "    '''\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "\n",
    "    x = Conv2D(64, (3, 3), padding='same', use_bias=False, kernel_initializer='he_normal',\n",
    "               kernel_regularizer=l2(weight_decay))(input)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def __initial_conv_block_imagenet(input, weight_decay=5e-4):\n",
    "    ''' Adds an initial conv block, with batch norm and relu for the inception resnext\n",
    "    Args:\n",
    "        input: input tensor\n",
    "        weight_decay: weight decay factor\n",
    "    Returns: a keras tensor\n",
    "    '''\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "\n",
    "    x = Conv2D(64, (7, 7), padding='same', use_bias=False, kernel_initializer='he_normal',\n",
    "               kernel_regularizer=l2(weight_decay), strides=(2, 2))(input)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def __grouped_convolution_block(input, grouped_channels, cardinality, strides, weight_decay=5e-4):\n",
    "    ''' Adds a grouped convolution block. It is an equivalent block from the paper\n",
    "    Args:\n",
    "        input: input tensor\n",
    "        grouped_channels: grouped number of filters\n",
    "        cardinality: cardinality factor describing the number of groups\n",
    "        strides: performs strided convolution for downscaling if > 1\n",
    "        weight_decay: weight decay term\n",
    "    Returns: a keras tensor\n",
    "    '''\n",
    "    init = input\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "\n",
    "    group_list = []\n",
    "\n",
    "    if cardinality == 1:\n",
    "        # with cardinality 1, it is a standard convolution\n",
    "        x = Conv2D(grouped_channels, (3, 3), padding='same', use_bias=False, strides=(strides, strides),\n",
    "                   kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay))(init)\n",
    "        x = BatchNormalization(axis=channel_axis)(x)\n",
    "        x = Activation('relu')(x)\n",
    "        return x\n",
    "\n",
    "    for c in range(cardinality):\n",
    "        x = Lambda(lambda z: z[:, :, :, c * grouped_channels:(c + 1) * grouped_channels]\n",
    "        if K.image_data_format() == 'channels_last' else\n",
    "        lambda z: z[:, c * grouped_channels:(c + 1) * grouped_channels, :, :])(input)\n",
    "\n",
    "        x = Conv2D(grouped_channels, (3, 3), padding='same', use_bias=False, strides=(strides, strides),\n",
    "                   kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay))(x)\n",
    "\n",
    "        group_list.append(x)\n",
    "\n",
    "    group_merge = concatenate(group_list, axis=channel_axis)\n",
    "    x = BatchNormalization(axis=channel_axis)(group_merge)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def __bottleneck_block(input, filters=64, cardinality=8, strides=1, weight_decay=5e-4):\n",
    "    ''' Adds a bottleneck block\n",
    "    Args:\n",
    "        input: input tensor\n",
    "        filters: number of output filters\n",
    "        cardinality: cardinality factor described number of\n",
    "            grouped convolutions\n",
    "        strides: performs strided convolution for downsampling if > 1\n",
    "        weight_decay: weight decay factor\n",
    "    Returns: a keras tensor\n",
    "    '''\n",
    "    init = input\n",
    "\n",
    "    grouped_channels = int(filters / cardinality)\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "\n",
    "    # Check if input number of filters is same as 16 * k, else create convolution2d for this input\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        if init._keras_shape[1] != 2 * filters:\n",
    "            init = Conv2D(filters * 2, (1, 1), padding='same', strides=(strides, strides),\n",
    "                          use_bias=False, kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay))(init)\n",
    "            init = BatchNormalization(axis=channel_axis)(init)\n",
    "    else:\n",
    "        if init._keras_shape[-1] != 2 * filters:\n",
    "            init = Conv2D(filters * 2, (1, 1), padding='same', strides=(strides, strides),\n",
    "                          use_bias=False, kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay))(init)\n",
    "            init = BatchNormalization(axis=channel_axis)(init)\n",
    "\n",
    "    x = Conv2D(filters, (1, 1), padding='same', use_bias=False,\n",
    "               kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay))(input)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = __grouped_convolution_block(x, grouped_channels, cardinality, strides, weight_decay)\n",
    "\n",
    "    x = Conv2D(filters * 2, (1, 1), padding='same', use_bias=False, kernel_initializer='he_normal',\n",
    "               kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "\n",
    "    x = add([init, x])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def __create_res_next(nb_classes, img_input, include_top, depth=29, cardinality=8, width=4,\n",
    "                      weight_decay=5e-4, pooling=None):\n",
    "    ''' Creates a ResNeXt model with specified parameters\n",
    "    Args:\n",
    "        nb_classes: Number of output classes\n",
    "        img_input: Input tensor or layer\n",
    "        include_top: Flag to include the last dense layer\n",
    "        depth: Depth of the network. Can be an positive integer or a list\n",
    "               Compute N = (n - 2) / 9.\n",
    "               For a depth of 56, n = 56, N = (56 - 2) / 9 = 6\n",
    "               For a depth of 101, n = 101, N = (101 - 2) / 9 = 11\n",
    "        cardinality: the size of the set of transformations.\n",
    "               Increasing cardinality improves classification accuracy,\n",
    "        width: Width of the network.\n",
    "        weight_decay: weight_decay (l2 norm)\n",
    "        pooling: Optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model will be\n",
    "                the 4D tensor output of the\n",
    "                last convolutional layer.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional layer, and thus\n",
    "                the output of the model will be a 2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "    Returns: a Keras Model\n",
    "    '''\n",
    "\n",
    "    if type(depth) is list or type(depth) is tuple:\n",
    "        # If a list is provided, defer to user how many blocks are present\n",
    "        N = list(depth)\n",
    "    else:\n",
    "        # Otherwise, default to 3 blocks each of default number of group convolution blocks\n",
    "        N = [(depth - 2) // 9 for _ in range(3)]\n",
    "\n",
    "    filters = cardinality * width\n",
    "    filters_list = []\n",
    "\n",
    "    for i in range(len(N)):\n",
    "        filters_list.append(filters)\n",
    "        filters *= 2  # double the size of the filters\n",
    "\n",
    "    x = __initial_conv_block(img_input, weight_decay)\n",
    "\n",
    "    # block 1 (no pooling)\n",
    "    for i in range(N[0]):\n",
    "        x = __bottleneck_block(x, filters_list[0], cardinality, strides=1, weight_decay=weight_decay)\n",
    "\n",
    "    N = N[1:]  # remove the first block from block definition list\n",
    "    filters_list = filters_list[1:]  # remove the first filter from the filter list\n",
    "\n",
    "    # block 2 to N\n",
    "    for block_idx, n_i in enumerate(N):\n",
    "        for i in range(n_i):\n",
    "            if i == 0:\n",
    "                x = __bottleneck_block(x, filters_list[block_idx], cardinality, strides=2,\n",
    "                                       weight_decay=weight_decay)\n",
    "            else:\n",
    "                x = __bottleneck_block(x, filters_list[block_idx], cardinality, strides=1,\n",
    "                                       weight_decay=weight_decay)\n",
    "\n",
    "    if include_top:\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(nb_classes, use_bias=False, kernel_regularizer=l2(weight_decay),\n",
    "                  kernel_initializer='he_normal', activation='softmax')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def __create_res_next_imagenet(nb_classes, img_input, include_top, depth, cardinality=32, width=4,\n",
    "                               weight_decay=5e-4, pooling=None):\n",
    "    ''' Creates a ResNeXt model with specified parameters\n",
    "    Args:\n",
    "        nb_classes: Number of output classes\n",
    "        img_input: Input tensor or layer\n",
    "        include_top: Flag to include the last dense layer\n",
    "        depth: Depth of the network. List of integers.\n",
    "               Increasing cardinality improves classification accuracy,\n",
    "        width: Width of the network.\n",
    "        weight_decay: weight_decay (l2 norm)\n",
    "        pooling: Optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model will be\n",
    "                the 4D tensor output of the\n",
    "                last convolutional layer.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional layer, and thus\n",
    "                the output of the model will be a 2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "    Returns: a Keras Model\n",
    "    '''\n",
    "\n",
    "    if type(depth) is list or type(depth) is tuple:\n",
    "        # If a list is provided, defer to user how many blocks are present\n",
    "        N = list(depth)\n",
    "    else:\n",
    "        # Otherwise, default to 3 blocks each of default number of group convolution blocks\n",
    "        N = [(depth - 2) // 9 for _ in range(3)]\n",
    "\n",
    "    filters = cardinality * width\n",
    "    filters_list = []\n",
    "\n",
    "    for i in range(len(N)):\n",
    "        filters_list.append(filters)\n",
    "        filters *= 2  # double the size of the filters\n",
    "\n",
    "    x = __initial_conv_block_imagenet(img_input, weight_decay)\n",
    "\n",
    "    # block 1 (no pooling)\n",
    "    for i in range(N[0]):\n",
    "        x = __bottleneck_block(x, filters_list[0], cardinality, strides=1, weight_decay=weight_decay)\n",
    "\n",
    "    N = N[1:]  # remove the first block from block definition list\n",
    "    filters_list = filters_list[1:]  # remove the first filter from the filter list\n",
    "\n",
    "    # block 2 to N\n",
    "    for block_idx, n_i in enumerate(N):\n",
    "        for i in range(n_i):\n",
    "            if i == 0:\n",
    "                x = __bottleneck_block(x, filters_list[block_idx], cardinality, strides=2,\n",
    "                                       weight_decay=weight_decay)\n",
    "            else:\n",
    "                x = __bottleneck_block(x, filters_list[block_idx], cardinality, strides=1,\n",
    "                                       weight_decay=weight_decay)\n",
    "\n",
    "    if include_top:\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(nb_classes, use_bias=False, kernel_regularizer=l2(weight_decay),\n",
    "                  kernel_initializer='he_normal', activation='softmax')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 200, 200, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 200, 200, 64) 1728        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 200, 200, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 200, 200, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 200, 200, 32) 2048        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 200, 200, 32) 128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 200, 200, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 200, 200, 8)  0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 200, 200, 8)  0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 200, 200, 8)  0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 200, 200, 8)  0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 200, 200, 8)  576         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 200, 200, 8)  576         lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 200, 200, 8)  576         lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 200, 200, 8)  576         lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 200, 200, 32) 0           conv2d_3[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 200, 200, 32) 128         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 200, 200, 32) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 200, 200, 64) 2048        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 200, 200, 64) 256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 200, 200, 64) 0           activation_1[0][0]               \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 200, 200, 64) 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 200, 200, 64) 4096        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 200, 200, 64) 256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 200, 200, 64) 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 200, 200, 16) 0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 200, 200, 16) 0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 200, 200, 16) 0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 200, 200, 16) 0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 100, 100, 16) 2304        lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 100, 100, 16) 2304        lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 100, 100, 16) 2304        lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 100, 100, 16) 2304        lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 100, 100, 64) 0           conv2d_10[0][0]                  \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 100, 100, 64) 256         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 100, 100, 64) 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 100, 100, 128 8192        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 100, 100, 128 8192        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 100, 100, 128 512         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 100, 100, 128 512         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 100, 100, 128 0           batch_normalization_5[0][0]      \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 100, 100, 128 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 100, 100, 128 16384       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 100, 100, 128 512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 100, 100, 128 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 100, 100, 32) 0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 100, 100, 32) 0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 100, 100, 32) 0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 100, 100, 32) 0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 50, 50, 32)   9216        lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 50, 50, 32)   9216        lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 50, 50, 32)   9216        lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 50, 50, 32)   9216        lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 50, 50, 128)  0           conv2d_17[0][0]                  \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 50, 50, 128)  512         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 50, 50, 128)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 50, 50, 256)  32768       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 50, 50, 256)  32768       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 50, 50, 256)  1024        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 50, 50, 256)  1024        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 50, 50, 256)  0           batch_normalization_9[0][0]      \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 50, 50, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 256)          0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 163)          41728       global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 203,712\n",
      "Trainable params: 201,024\n",
      "Non-trainable params: 2,688\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "image_shape = (200, 200, 3)\n",
    "depth=11\n",
    "cardinality=4\n",
    "width=8\n",
    "model = ResNext(image_shape, depth = depth, cardinality = cardinality, width = width, classes = 163)\n",
    "adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics = [\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79528 images belonging to 163 classes.\n",
      "Found 57114 images belonging to 163 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train_images',\n",
    "        target_size=(200, 200),\n",
    "        batch_size=32)\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'data/test_images',\n",
    "        target_size=(200, 200),\n",
    "        batch_size=32)\n",
    "csv_logger = keras.callbacks.CSVLogger('training.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  19/2485 [..............................] - ETA: 57:37 - loss: 6.4539 - acc: 0.0197"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    epochs=100,\n",
    "                    steps_per_epoch=train_generator.samples // train_generator.batch_size, \n",
    "                    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "                    workers=16,\n",
    "                    callbacks=[csv_logger],\n",
    "                    use_multiprocessing=True)\n",
    "model.save(\"resnext50.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'channels_last'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.image_data_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
